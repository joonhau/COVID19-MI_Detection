{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data path\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/CT'\n",
    "data_dir_list = os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image processing ##\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "num_channel=1\n",
    "num_classes = 2\n",
    "labels_name={'Covid':0,'non-Covid':1}\n",
    "\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    label = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(IMG_WIDTH,IMG_HEIGHT))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image normalization ##\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Label one hot encoding ##\n",
    "labels = np.array(labels_list)\n",
    "print(np.unique(labels,return_counts=True))\n",
    "Y = np_utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialization of pre-trained ResNet50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import AveragePooling2D\n",
    "\n",
    "# include top should be False to remove the softmax layer\n",
    "pretrained_model = ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "## Output based on average_pooling2d_1 ##\n",
    "output = pretrained_model.layers[-33].output\n",
    "output = keras.layers.AveragePooling2D((1,1))(output)\n",
    "pretrained_model = keras.Model(pretrained_model.input, output)\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features extraction ##\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "vgg_features_train = pretrained_model.predict(X_train) #train features\n",
    "vgg_features_val = pretrained_model.predict(X_test)    #val features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fully Connected Layers ###\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(14, 14, 1024)))\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(BatchNormalization(momentum=0.8))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer=keras.optimizers.adam(lr=0.0003, decay= 1e-5) , metrics=['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "# anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "# checkpoint = ModelCheckpoint('model/ResNet_Classifier.h5', verbose=1, save_best_only=True)\n",
    "#callbacks=[anne, checkpoint]\n",
    "# train model using features generated from VGG16 model\n",
    "\n",
    "hist = model2.fit(vgg_features_train, y_train, epochs=100, batch_size=128, validation_data=(vgg_features_val, y_test))\n",
    "#model2.save('model/ResNet_Classifier_AveragePooling2D.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving training acc and loss to CSV\n",
    "hist_df = pd.DataFrame(hist.history) \n",
    "\n",
    "hist_csv_file = 'history/Resnet_history.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "    \n",
    "history = pd.read_csv(\"history/Resnet_history.csv\")\n",
    "val_loss = history['val_loss'].to_numpy()\n",
    "val_acc = history['val_accuracy'].to_numpy()\n",
    "loss = history['loss'].to_numpy()\n",
    "acc = history['accuracy'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLotting acc vs loss ##\n",
    "plt.plot(acc)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Training Accuracy', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Accuracy (%)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.legend(['Train_acc', 'Train_loss', 'Val_acc', 'Val_loss'], loc='best', fontsize=22)\n",
    "plt.gcf().set_size_inches(15,10) \n",
    "plt.savefig('C:/Users/CooL/Desktop/Result/VGG/Resnet_train_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/Testing_Set'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "test_list = []\n",
    "y_pred = []\n",
    "labels_name ={'Covid':0,'non-Covid':1}\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    label = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(IMG_WIDTH,IMG_HEIGHT))\n",
    "        test_list.append(input_img_resize)\n",
    "        y_pred.append(label)\n",
    "\n",
    "test_image = np.array(test_list)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "\n",
    "test_features = pretrained_model.predict(test_image)\n",
    "\n",
    "\n",
    "predict_list = []\n",
    "predict_1 = model2.predict_proba(test_features)\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_pred, predict_1[:,1])\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import pandas as pd\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "optimum = thresholds_keras[np.argmax(tpr_keras - fpr_keras)]\n",
    "print('Optimal cut off point = ',optimum)\n",
    "print('AUC = ', auc_keras)\n",
    "\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "ix = np.argmax(gmeans)\n",
    "optimal = thresholds_keras[ix]\n",
    "print('Optimal cut off point = ',thresholds_keras[ix])\n",
    "\n",
    "\n",
    "x = optimal # Best => x = 0.98892\n",
    "\n",
    "for j in range(0,1):\n",
    "    for i in range(0, len(predict_1)):\n",
    "        if predict_1[i][1] >= x:\n",
    "            predict_list.append(1)\n",
    "        else:\n",
    "            predict_list.append(0)\n",
    "    print(confusion_matrix(y_pred, predict_list), 'x =',\"%.5f\" % x, '\\n')\n",
    "\n",
    "cf_matrix=confusion_matrix(y_pred, predict_list)\n",
    "tp = cf_matrix[0][0]\n",
    "fn = cf_matrix[0][1]\n",
    "fp = cf_matrix[1][0]\n",
    "tn = cf_matrix[1][1]\n",
    "\n",
    "TrueP = '{0:.2%}'.format(tp/(tp+fn))\n",
    "FalseN = '{0:.2%}'.format(fn/(tp+fn))\n",
    "FalseP = '{0:.2%}'.format(fp/(fp+tn))\n",
    "TrueN = '{0:.2%}'.format(tn/(fp+tn))\n",
    "print(TrueP, FalseN, FalseP, TrueN)\n",
    "\n",
    "xy_Labels = ['Covid', 'non-Covid']\n",
    "group_names = ['True Positive', 'False Negative', 'False Positive','True Negative']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentage = [TrueP, FalseN, FalseP, TrueN]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentage)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "### Confusion Matrix of ResNet50 ###\n",
    "# plt.title('(ResNet-50), Threshold = '+str(\"{:.4f}\".format(optimal)), fontsize = 20)\n",
    "plt.title('Confusion Matrix (ResNet-50)',fontsize = 18)\n",
    "sns.heatmap(cf_matrix, fmt='', annot=labels, annot_kws={'size':18} ,xticklabels=xy_Labels, yticklabels=xy_Labels, cmap='Blues')\n",
    "plt.xlabel('Predicted label', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True label', fontsize = 15) # y-axis label with fontsize 15\n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/Resnet/Resnet_CF.jpg')\n",
    "plt.show()\n",
    "\n",
    "### ROC Curves ResNet50 ###\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix],tpr_keras[ix], marker='o', color='black', label='Optimal Threshold = {:.4f})'.format(optimal))\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.title('ROC (ResNet-50)',fontsize=22)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/Resnet/Resnet_graph.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
