{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPool2D, Flatten, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import roberts, farid, sobel, scharr, prewitt, laplace\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import area_closing, disk, dilation, binary_erosion, remove_small_objects, erosion, opening, closing, reconstruction, binary_closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define path ##\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/CT'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "num_channel=1\n",
    "num_classes = 2\n",
    "labels_name={'Covid':0,'non-Covid':1}\n",
    "\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "\n",
    "## Retrieval of images and labels\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    label_data = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        im3= cv2.imread(data_path + '/'+ dataset + '/'+ img , 0)\n",
    "        im2= cv2.imread(data_path + '/'+ dataset + '/'+ img , 0)\n",
    "        im= cv2.imread(data_path + '/'+ dataset + '/'+ img , 0)\n",
    "        ret1,th1 = cv2.threshold(im, 127,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        h,w = im.shape[0:2]\n",
    "        mask = np.zeros(im.shape, dtype=np.uint8)\n",
    "\n",
    "        left = int(np.round(h/(2)))\n",
    "        right = int(np.round(h/(2)))\n",
    "        for y in range(left-int(h/5.2), left+int(h/3.9)):\n",
    "            for x in range(0, 4):\n",
    "                im[y][x] = 255\n",
    "\n",
    "        for y in range(right-int(h/5.2), right+int(h/3.9)):\n",
    "                for x in range(w-4, w):\n",
    "                    im[y][x] = 255\n",
    "        \n",
    "        ret1,im2 = cv2.threshold(im2,180,180, cv2.THRESH_TOZERO)   \n",
    "        ## Binary image ##\n",
    "        binary = im < 150\n",
    "\n",
    "        ## Remove the blobs connected to the border of the image ##\n",
    "        cleared = clear_border(binary)\n",
    "\n",
    "        ## Label image ##\n",
    "        label_image = label(cleared)\n",
    "\n",
    "\n",
    "        ## Keep the labels with 2 largest areas ##\n",
    "        areas = [r.area for r in regionprops(label_image)]\n",
    "        areas.sort()\n",
    "\n",
    "\n",
    "        if len(areas) > 2:\n",
    "            for region in regionprops(label_image):\n",
    "                if region.area <= 5:\n",
    "                    for coordinates in region.coords: \n",
    "                        label_image[coordinates[0], coordinates[1]] = 0\n",
    "                        mask[coordinates[0], coordinates[1]] = 255\n",
    "\n",
    "\n",
    "        large_binary = label_image > 0  \n",
    "\n",
    "        ## Erosion operation with a disk of radius 2. This operation is seperate the lung nodules attached to the blood vessels ##\n",
    "        selem = disk(0)\n",
    "        binary_eroded = binary_erosion(large_binary, selem)\n",
    "\n",
    "\n",
    "        ## Closure operation with a disk of radius 10. This operation is to keep nodules attached to the lung wall ##\n",
    "        selem = disk(10)\n",
    "        binary_closed = binary_closing(binary_eroded, selem)\n",
    "\n",
    "        start_point = (0, 0) \n",
    "        end_point = (0,h) \n",
    "        color = (0,0,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point, end_point, color, 5)\n",
    "\n",
    "        start_point2 = (w, 0) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, h) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, 0) \n",
    "        end_point2 = (w,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "\n",
    "        ## Fill in the small holes inside the binary mask of lungs ##\n",
    "        edges = roberts(binary_closed)\n",
    "        hole_closed = ndi.binary_fill_holes(edges)\n",
    "\n",
    "        ## Superimpose the binary mask on the input image. ##\n",
    "        ZERO_VALUE = 0\n",
    "        get_high_vals = (hole_closed == 0)\n",
    "        im[get_high_vals] = ZERO_VALUE # minimum value\n",
    "        \n",
    "                \n",
    "        input_img_resize=cv2.resize(im,(224,224))\n",
    "        input_img_resize_gray = cv2.resize(im3,(224,224))\n",
    "        moments = cv2.moments(input_img_resize_gray)\n",
    "        huMoments = cv2.HuMoments(moments)   \n",
    "        moment_list.append(huMoments)\n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(label_data)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image normalization\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "moment_data = np.array(moment_list)\n",
    "moment_data = moment_data.astype('float32')\n",
    "moment_data /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "labels = np.array(labels_list)\n",
    "print(np.unique(labels,return_counts=True))\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color channel expansion for gray images ##\n",
    "if num_channel==1:\n",
    "    if K.common.image_dim_ordering()=='th':\n",
    "        img_data= np.expand_dims(img_data, axis=1) \n",
    "        moment_data= np.expand_dims(moment_data, axis=1) \n",
    "        print (img_data.shape)\n",
    "    else:\n",
    "        img_data= np.expand_dims(img_data, axis=3) \n",
    "        moment_data= np.expand_dims(moment_data, axis=3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "x2,y2 = shuffle(moment_data,Y, random_state=2)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert train and test set to RGB\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_train = tf.image.grayscale_to_rgb(X_train)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "X_test = tf.image.grayscale_to_rgb(X_test)\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(X_train)\n",
    "X_train = tf.make_ndarray(proto_tensor_val)\n",
    "print(X_train.shape)\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(X_test)\n",
    "X_test = tf.make_ndarray(proto_tensor_val)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VGG16 initialization ###\n",
    "\n",
    "# include top should be False to remove the softmax layer\n",
    "pretrained_model = VGG16(include_top=False, weights='imagenet')\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature extraction on train and val set\n",
    "\n",
    "vgg_features_train = pretrained_model.predict(X_train)\n",
    "vgg_features_val = pretrained_model.predict(X_test)\n",
    "\n",
    "vgg_features_train = vgg_features_train.reshape(2052,25088,1)\n",
    "vgg_features_val = vgg_features_val.reshape(228,25088,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape moment invariant 1 (training) values into 1 dimension\n",
    "X_train2_1 = X_train2\n",
    "Moment_Inv = X_train2_1.reshape(2052,7,1)\n",
    "VGG_MI = K.concatenate([vgg_features_train, Moment_Inv],axis=1)\n",
    "\n",
    "# Reshape moment invariant 1 (testing) values into 1 dimension\n",
    "X_test2_1 = X_test2\n",
    "Moment_Inv_val = X_test2_1.reshape(228,7,1)\n",
    "VGG_MI_val = K.concatenate([vgg_features_val, Moment_Inv_val],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "proto_tensor = tf.make_tensor_proto(VGG_MI)\n",
    "input_array = tf.make_ndarray(proto_tensor)\n",
    "input_array_shape = input_array[0].shape\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(VGG_MI_val)\n",
    "input_array_val = tf.make_ndarray(proto_tensor_val)\n",
    "print(input_array_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Fully Connected layer\n",
    "model_fusion = Sequential()\n",
    "\n",
    "#model_fusion.build(input_array_shape)\n",
    "model_fusion.add(Flatten(input_shape=(25095,1)))\n",
    "model_fusion.add(Dense(256, activation='relu'))\n",
    "model_fusion.add(Dropout(0.5))\n",
    "model_fusion.add(BatchNormalization())\n",
    "model_fusion.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay= 1e-8, momentum= 0.4, nesterov=True)\n",
    "# model_fusion.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "# sgd = SGD(lr=0.00004, decay= 1e-7, momentum= 0.4, nesterov=True)\n",
    "# model_fusion.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, verbose=1, min_lr=1e-3)\n",
    "checkpoint = ModelCheckpoint('model/VGG_Moment_Classifier2.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "model_fusion.compile(loss='binary_crossentropy', optimizer=adam(lr=0.00005, decay= 1e-5), metrics=['accuracy'])\n",
    "model_fusion.summary()\n",
    "Fusion = model_fusion.fit(input_array, y_train, batch_size = 224 , epochs=100, verbose=1, validation_data=(input_array_val, y_test),callbacks=[anne, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving training output to CSV file\n",
    "hist_df = pd.DataFrame(Fusion.history) \n",
    "\n",
    "hist_csv_file = 'history/VGG_MI_Seg_history2.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "history = pd.read_csv(\"history/VGG_MI_Seg_history2.csv\")\n",
    "val_loss = history['val_loss'].to_numpy()\n",
    "val_acc = history['val_accuracy'].to_numpy()\n",
    "loss = history['loss'].to_numpy()\n",
    "acc = history['accuracy'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(acc)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Training Accuracy vs Epochs (VGG16 + MI + Segmentation)', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Accuracy (%)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.legend(['Train_acc', 'Train_loss', 'Val_acc', 'Val_loss'], loc='best', fontsize=22)\n",
    "plt.gcf().set_size_inches(12,10) \n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/All Training vs Loss/VGG_MI_train_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Testing phase VGG16+ MI ####\n",
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/Testing_Set'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_list = []\n",
    "moment_list2 = []\n",
    "y_pred = []\n",
    "labels_name ={'Covid-19':0,'Non-Covid-19':1}\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    label_data = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        im = cv2.imread(data_path + '/'+ dataset + '/'+ img, 0 )\n",
    "        im3 = cv2.imread(data_path + '/'+ dataset + '/'+ img, 0 )\n",
    "        h,w = im.shape[0:2]\n",
    "        mask = np.zeros(im.shape, dtype=np.uint8)\n",
    "\n",
    "        left = int(np.round(h/(2)))\n",
    "        right = int(np.round(h/(2)))\n",
    "        for y in range(left-int(h/5.2), left+int(h/3.9)):\n",
    "            for x in range(0, 4):\n",
    "                im[y][x] = 255\n",
    "\n",
    "        for y in range(right-int(h/5.2), right+int(h/3.9)):\n",
    "                for x in range(w-4, w):\n",
    "                    im[y][x] = 255\n",
    "\n",
    "        ## Binary image ##\n",
    "        binary = im < 150\n",
    "\n",
    "        ## Remove the blobs connected to the border of the image ##\n",
    "        cleared = clear_border(binary)\n",
    "\n",
    "        ## Label image ##\n",
    "        label_image = label(cleared)\n",
    "\n",
    "\n",
    "        ## Keep the labels with 2 largest areas ##\n",
    "        areas = [r.area for r in regionprops(label_image)]\n",
    "        areas.sort()\n",
    "\n",
    "\n",
    "        if len(areas) > 2:\n",
    "            for region in regionprops(label_image):\n",
    "                if region.area <= 5:\n",
    "                    for coordinates in region.coords: \n",
    "                        label_image[coordinates[0], coordinates[1]] = 0\n",
    "                        mask[coordinates[0], coordinates[1]] = 255\n",
    "\n",
    "\n",
    "        large_binary = label_image > 0  \n",
    "\n",
    "        ## Erosion operation with a disk of radius 2. This operation is seperate the lung nodules attached to the blood vessels ##\n",
    "        selem = disk(0)\n",
    "        binary_eroded = binary_erosion(large_binary, selem)\n",
    "\n",
    "\n",
    "        ## Closure operation with a disk of radius 10. This operation is to keep nodules attached to the lung wall ##\n",
    "        selem = disk(10)\n",
    "        binary_closed = binary_closing(binary_eroded, selem)\n",
    "\n",
    "        start_point = (0, 0) \n",
    "        end_point = (0,h) \n",
    "        color = (0,0,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point, end_point, color, 5)\n",
    "\n",
    "        start_point2 = (w, 0) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, h) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, 0) \n",
    "        end_point2 = (w,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "\n",
    "        ## Fill in the small holes inside the binary mask of lungs ##\n",
    "        edges = roberts(binary_closed)\n",
    "        hole_closed = ndi.binary_fill_holes(edges)\n",
    "\n",
    "        ## Superimpose the binary mask on the input image. ##\n",
    "        ZERO_VALUE = 0\n",
    "        get_high_vals = (hole_closed == 0)\n",
    "        im[get_high_vals] = ZERO_VALUE # minimum value\n",
    "        \n",
    "        input_img_resize = cv2.resize(im,(224,224))\n",
    "        input_img_resize_gray = cv2.resize(im3,(224,224))\n",
    "        moments = cv2.moments(input_img_resize_gray)\n",
    "        huMoments = cv2.HuMoments(moments)   \n",
    "        moment_list2.append(huMoments)\n",
    "        test_list.append(input_img_resize)\n",
    "        y_pred.append(label_data)\n",
    "\n",
    "test_image = np.array(test_list)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "moment_data = np.array(moment_list2)\n",
    "moment_data = moment_data.astype('float32')\n",
    "moment_data /= 255\n",
    "\n",
    "if num_channel==1:\n",
    "    if K.common.image_dim_ordering()=='th':\n",
    "        test_image= np.expand_dims(test_image, axis=1) \n",
    "        moment_data= np.expand_dims(moment_data, axis=1) \n",
    "        print (test_image.shape)\n",
    "    else:\n",
    "        test_image= np.expand_dims(test_image, axis=3) \n",
    "        moment_data= np.expand_dims(moment_data, axis=3) \n",
    "        print (test_image.shape)\n",
    "        print (moment_data.shape)\n",
    "\n",
    "\n",
    "VGG_features_test = pretrained_model.predict(test_image)\n",
    "VGG_features_test = VGG_features_test.reshape(200,25088,1)\n",
    "#predict = np.argmax(Resnet_features_test,axis=1)\n",
    "\n",
    "\n",
    "Moment_Inv_test = moment_data.reshape(200,7,1)\n",
    "VGG_MI_test = K.concatenate([VGG_features_test, Moment_Inv_test],axis=1)\n",
    "\n",
    "\n",
    "proto_tensor = tf.make_tensor_proto(VGG_MI_test)\n",
    "input_array_test = tf.make_ndarray(proto_tensor)\n",
    "input_array_shape = input_array[0].shape\n",
    "\n",
    "predicted_test = model_fusion.predict(input_array_test)\n",
    "predict = np.argmax(predicted_test,axis=1)\n",
    "\n",
    "# # predict = overall.predict(input_array)\n",
    "# # predict = np.argmax(predict,axis=1)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_pred, predict)\n",
    "tp = cf_matrix[0][0]\n",
    "fn = cf_matrix[0][1]\n",
    "fp = cf_matrix[1][0]\n",
    "tn = cf_matrix[1][1]\n",
    "\n",
    "TrueP = '{0:.2%}'.format(tp/(tp+fn))\n",
    "FalseN = '{0:.2%}'.format(fn/(tp+fn))\n",
    "FalseP = '{0:.2%}'.format(fp/(fp+tn))\n",
    "TrueN = '{0:.2%}'.format(tn/(fp+tn))\n",
    "print(TrueP, FalseN, FalseP, TrueN)\n",
    "\n",
    "xy_Labels = ['Covid', 'non-Covid']\n",
    "group_names = ['True Positive', 'False Negative', 'False Positive','True Negative']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentage = [TrueP, FalseN, FalseP, TrueN]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentage)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "## Confusion matrix VGG16 + MI + Segmentation ##\n",
    "plt.title('(Moment Invariant + VGG-16 + Segmentation)', fontsize = 18)\n",
    "sns.heatmap(cf_matrix, fmt='', annot=labels, annot_kws={'size':18} ,xticklabels=xy_Labels, yticklabels=xy_Labels, cmap='PuBuGn')\n",
    "plt.xlabel('Predicted label', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True label', fontsize = 15) # y-axis label with fontsize 15\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import pandas as pd\n",
    "\n",
    "predict_list = []\n",
    "predict_1 = model2.predict(input_array_test)\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_pred, predict_1[:,1])\n",
    "\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "optimum = thresholds_keras[np.argmax(tpr_keras - fpr_keras)]\n",
    "print('Optimal cut off point = ',optimum)\n",
    "print('AUC = ', auc_keras)\n",
    "\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "ix = np.argmax(gmeans)\n",
    "optimal = thresholds_keras[ix]\n",
    "print('Optimal cut off point = ',thresholds_keras[ix])\n",
    "\n",
    "x = optimal # Best => x = 0.98892\n",
    "\n",
    "\n",
    "\n",
    "### ROC Curves VGG16 + MI + Segmentation ###\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix],tpr_keras[ix], marker='o', color='black', label='Optimal Threshold = {:.4f})'.format(optimal))\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.title('ROC (VGG-16 + Moment Invariant + Segmentation)',fontsize=22)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/VGG_Moment Invariant/VGG_MIgraph.jpg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
