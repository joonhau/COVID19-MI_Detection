{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import GlobalAveragePooling2D, GlobalMaxPool2D, Flatten, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define path ##\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/CT'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "num_channel=1\n",
    "num_classes = 2\n",
    "labels_name={'Covid':0,'non-Covid':1}\n",
    "\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "\n",
    "## Retrieval of images and labels\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    label = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        input_img = cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_gray = cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize = cv2.resize(input_img,(224,224))\n",
    "        \n",
    "        input_img_resize_gray =cv2.resize(input_img_gray,(224,224))\n",
    "        _, input_img_resize_gray = cv2.threshold(input_img_resize_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        moments = cv2.moments(input_img_resize_gray)\n",
    "        huMoments = cv2.HuMoments(moments)   \n",
    "        moment_list.append(huMoments)\n",
    "              \n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image normalization\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "moment_data = np.array(moment_list)\n",
    "moment_data = moment_data.astype('float32')\n",
    "moment_data /= 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "labels = np.array(labels_list)\n",
    "print(np.unique(labels,return_counts=True))\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color channel expansion for gray images ##\n",
    "if num_channel==1:\n",
    "    if K.common.image_dim_ordering()=='th':\n",
    "        moment_data= np.expand_dims(moment_data, axis=1) \n",
    "    else:\n",
    "        moment_data= np.expand_dims(moment_data, axis=3) \n",
    "else:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.rollaxis(img_data,3,1)\n",
    "        print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "x2,y2 = shuffle(moment_data,Y, random_state=2)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VGG16 initialization ###\n",
    "\n",
    "# include top should be False to remove the softmax layer\n",
    "pretrained_model = VGG16(include_top=False, weights='imagenet')\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature extraction on train and val set\n",
    "\n",
    "vgg_features_train = pretrained_model.predict(X_train)\n",
    "vgg_features_val = pretrained_model.predict(X_test)\n",
    "\n",
    "vgg_features_train = vgg_features_train.reshape(2052,25088,1)\n",
    "vgg_features_val = vgg_features_val.reshape(228,25088,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape moment invariant 1 (training) values into 1 dimension\n",
    "X_train2_1 = X_train2\n",
    "Moment_Inv = X_train2_1.reshape(2052,7,1)\n",
    "VGG_MI = K.concatenate([vgg_features_train, Moment_Inv],axis=1)\n",
    "\n",
    "# Reshape moment invariant 1 (testing) values into 1 dimension\n",
    "X_test2_1 = X_test2\n",
    "Moment_Inv_val = X_test2_1.reshape(228,7,1)\n",
    "VGG_MI_val = K.concatenate([vgg_features_val, Moment_Inv_val],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "proto_tensor = tf.make_tensor_proto(VGG_MI)\n",
    "input_array = tf.make_ndarray(proto_tensor)\n",
    "input_array_shape = input_array[0].shape\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(VGG_MI_val)\n",
    "input_array_val = tf.make_ndarray(proto_tensor_val)\n",
    "print(input_array_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Fully Connected layer\n",
    "model_fusion = Sequential()\n",
    "\n",
    "#model_fusion.build(input_array_shape)\n",
    "model_fusion.add(Flatten(input_shape=(25095,1)))\n",
    "model_fusion.add(Dense(256, activation='relu'))\n",
    "model_fusion.add(Dropout(0.5))\n",
    "model_fusion.add(BatchNormalization())\n",
    "model_fusion.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay= 1e-8, momentum= 0.4, nesterov=True)\n",
    "# model_fusion.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "\n",
    "# sgd = SGD(lr=0.00004, decay= 1e-7, momentum= 0.4, nesterov=True)\n",
    "# model_fusion.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[\"accuracy\"])\n",
    "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=5, verbose=1, min_lr=1e-3)\n",
    "checkpoint = ModelCheckpoint('model/VGG_Moment_Classifier2.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "model_fusion.compile(loss='binary_crossentropy', optimizer=adam(lr=0.00005, decay= 1e-5), metrics=['accuracy'])\n",
    "model_fusion.summary()\n",
    "Fusion = model_fusion.fit(input_array, y_train, batch_size = 224 , epochs=100, verbose=1, validation_data=(input_array_val, y_test),callbacks=[anne, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving training output to CSV file\n",
    "hist_df = pd.DataFrame(Fusion.history) \n",
    "\n",
    "hist_csv_file = 'history/VGG_MI_history2.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "history = pd.read_csv(\"history/VGG_MI_history2.csv\")\n",
    "val_loss = history['val_loss'].to_numpy()\n",
    "val_acc = history['val_accuracy'].to_numpy()\n",
    "loss = history['loss'].to_numpy()\n",
    "acc = history['accuracy'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(acc)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Training Accuracy vs Epochs (VGG16 + MI)', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Accuracy (%)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.legend(['Train_acc', 'Train_loss', 'Val_acc', 'Val_loss'], loc='best', fontsize=22)\n",
    "plt.gcf().set_size_inches(12,10) \n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/All Training vs Loss/VGG_MI_train_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#### Testing phase VGG16+ MI ####\n",
    "PATH = os.getcwd()\n",
    "# Define data path\n",
    "data_path = PATH + '/Testing_Set'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_list = []\n",
    "moment_test_list = []\n",
    "moment_test_list2 = []\n",
    "y_pred = []\n",
    "labels_name ={'Covid-19':0,'Non-Covid-19':1}\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    label = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_resize=cv2.resize(input_img,(224,224))\n",
    "        input_img_moment =cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)     \n",
    "        moments = cv2.moments(input_img_moment)\n",
    "        huMoments = cv2.HuMoments(moments)  \n",
    "        moment_test_list.append(huMoments)       \n",
    "        test_list.append(input_img_resize)\n",
    "        y_pred.append(label)\n",
    "\n",
    "test_image = np.array(test_list)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "moment_data = np.array(moment_test_list)\n",
    "moment_data = moment_data.astype('float32')\n",
    "moment_data /= 255\n",
    "\n",
    "\n",
    "VGG_features_test = pretrained_model.predict(test_image)\n",
    "VGG_features_test = VGG_features_test.reshape(200,25088,1)\n",
    "#predict = np.argmax(Resnet_features_test,axis=1)\n",
    "\n",
    "\n",
    "Moment_Inv_test = moment_data.reshape(200,7,1)\n",
    "VGG_MI_test = K.concatenate([VGG_features_test, Moment_Inv_test],axis=1)\n",
    "\n",
    "\n",
    "proto_tensor = tf.make_tensor_proto(VGG_MI_test)\n",
    "input_array_test = tf.make_ndarray(proto_tensor)\n",
    "input_array_shape = input_array[0].shape\n",
    "\n",
    "predicted_test = model2.predict(input_array_test)\n",
    "predict = np.argmax(predicted_test,axis=1)\n",
    "\n",
    "# # predict = overall.predict(input_array)\n",
    "# # predict = np.argmax(predict,axis=1)\n",
    "\n",
    "cf_matrix = confusion_matrix(y_pred, predict)\n",
    "tp = cf_matrix[0][0]\n",
    "fn = cf_matrix[0][1]\n",
    "fp = cf_matrix[1][0]\n",
    "tn = cf_matrix[1][1]\n",
    "\n",
    "TrueP = '{0:.2%}'.format(tp/(tp+fn))\n",
    "FalseN = '{0:.2%}'.format(fn/(tp+fn))\n",
    "FalseP = '{0:.2%}'.format(fp/(fp+tn))\n",
    "TrueN = '{0:.2%}'.format(tn/(fp+tn))\n",
    "print(TrueP, FalseN, FalseP, TrueN)\n",
    "\n",
    "xy_Labels = ['Covid', 'non-Covid']\n",
    "group_names = ['True Positive', 'False Negative', 'False Positive','True Negative']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentage = [TrueP, FalseN, FalseP, TrueN]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentage)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "## Confusion matrix VGG16 + MI ##\n",
    "plt.title('(Moment Invariant + VGG-16)', fontsize = 18)\n",
    "sns.heatmap(cf_matrix, fmt='', annot=labels, annot_kws={'size':18} ,xticklabels=xy_Labels, yticklabels=xy_Labels, cmap='PuBuGn')\n",
    "plt.xlabel('Predicted label', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True label', fontsize = 15) # y-axis label with fontsize 15\n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/VGG_Moment Invariant/VGG_Mi_CF.jpg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "import pandas as pd\n",
    "\n",
    "predict_list = []\n",
    "predict_1 = model2.predict(input_array_test)\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_pred, predict_1[:,1])\n",
    "\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "optimum = thresholds_keras[np.argmax(tpr_keras - fpr_keras)]\n",
    "print('Optimal cut off point = ',optimum)\n",
    "print('AUC = ', auc_keras)\n",
    "\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "ix = np.argmax(gmeans)\n",
    "optimal = thresholds_keras[ix]\n",
    "print('Optimal cut off point = ',thresholds_keras[ix])\n",
    "\n",
    "x = optimal # Best => x = 0.98892\n",
    "\n",
    "# for j in range(0,21):\n",
    "#     for i in range(0, len(predict_1)):\n",
    "#         if predict_1[i][1] >= x:\n",
    "#             predict_list.append(1)\n",
    "#         else:\n",
    "#             predict_list.append(0)\n",
    "#     print(confusion_matrix(y_pred, predict_list), 'x =',\"%.5f\" % x, '\\n')\n",
    "#     predict_list.clear()\n",
    "#     x+=0.01\n",
    "\n",
    "\n",
    "\n",
    "### ROC Curves ###\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix],tpr_keras[ix], marker='o', color='black', label='Optimal Threshold = {:.4f})'.format(optimal))\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.title('ROC (VGG-16 + Moment Invariant)',fontsize=22)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/VGG_Moment Invariant/VGG_MIgraph.jpg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
