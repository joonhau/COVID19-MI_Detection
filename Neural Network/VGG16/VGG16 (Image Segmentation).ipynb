{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import canny\n",
    "from skimage.filters import roberts, farid, sobel, scharr, prewitt, laplace\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import area_closing, disk, dilation, binary_erosion, remove_small_objects, erosion, opening, closing, reconstruction, binary_closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the images of dataset-Covid\n",
      "\n",
      "Loaded the images of dataset-non-Covid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Define path ##\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/CT'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "IMG_WIDTH=224\n",
    "IMG_HEIGHT=224\n",
    "\n",
    "IMG_DIM = (IMG_WIDTH, IMG_HEIGHT)\n",
    "num_channel=1\n",
    "num_classes = 2\n",
    "labels_name={'Covid':0,'non-Covid':1}\n",
    "\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "\n",
    "## Retrieval of images and labels\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    label_data = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        im2= cv2.imread(data_path + '/'+ dataset + '/'+ img , 0)\n",
    "        im= cv2.imread(data_path + '/'+ dataset + '/'+ img , 0)\n",
    "        ret1,th1 = cv2.threshold(im, 127,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        h,w = im.shape[0:2]\n",
    "        mask = np.zeros(im.shape, dtype=np.uint8)\n",
    "\n",
    "        left = int(np.round(h/(2)))\n",
    "        right = int(np.round(h/(2)))\n",
    "        for y in range(left-int(h/5.2), left+int(h/3.9)):\n",
    "            for x in range(0, 4):\n",
    "                im[y][x] = 255\n",
    "\n",
    "        for y in range(right-int(h/5.2), right+int(h/3.9)):\n",
    "                for x in range(w-4, w):\n",
    "                    im[y][x] = 255\n",
    "        \n",
    "        ret1,im2 = cv2.threshold(im2,180,180, cv2.THRESH_TOZERO)   \n",
    "        ## Binary image ##\n",
    "        binary = im2 < 150\n",
    "\n",
    "        ## Remove the blobs connected to the border of the image ##\n",
    "        cleared = clear_border(binary)\n",
    "\n",
    "        ## Label image ##\n",
    "        label_image = label(cleared)\n",
    "\n",
    "\n",
    "        ## Keep the labels with 2 largest areas ##\n",
    "        areas = [r.area for r in regionprops(label_image)]\n",
    "        areas.sort()\n",
    "\n",
    "\n",
    "        if len(areas) > 2:\n",
    "            for region in regionprops(label_image):\n",
    "                if region.area <= 5:\n",
    "                    for coordinates in region.coords: \n",
    "                        label_image[coordinates[0], coordinates[1]] = 0\n",
    "                        mask[coordinates[0], coordinates[1]] = 255\n",
    "\n",
    "\n",
    "        large_binary = label_image > 0  \n",
    "\n",
    "        ## Erosion operation with a disk of radius 2. This operation is seperate the lung nodules attached to the blood vessels ##\n",
    "        selem = disk(0)\n",
    "        binary_eroded = binary_erosion(large_binary, selem)\n",
    "\n",
    "\n",
    "        ## Closure operation with a disk of radius 10. This operation is to keep nodules attached to the lung wall ##\n",
    "        selem = disk(9)\n",
    "        binary_closed = binary_closing(binary_eroded, selem)\n",
    "\n",
    "        start_point = (0, 0) \n",
    "        end_point = (0,h) \n",
    "        color = (0,0,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point, end_point, color, 5)\n",
    "\n",
    "        start_point2 = (w, 0) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, h) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, 0) \n",
    "        end_point2 = (w,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "\n",
    "        ## Fill in the small holes inside the binary mask of lungs ##\n",
    "        edges = roberts(binary_closed)\n",
    "        hole_closed = ndi.binary_fill_holes(edges)\n",
    "\n",
    "        ## Superimpose the binary mask on the input image. ##\n",
    "        ZERO_VALUE = 0\n",
    "        get_high_vals = (hole_closed == 0)\n",
    "        im[get_high_vals] = ZERO_VALUE # minimum value\n",
    "        \n",
    "                \n",
    "        input_img_resize=cv2.resize(im,(224,224))\n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(label_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2280, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "## Image normalization\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_channel==1:\n",
    "    if K.common.image_dim_ordering()=='th':\n",
    "        img_data= np.expand_dims(img_data, axis=1) \n",
    "#         moment_data= np.expand_dims(moment_data, axis=1) \n",
    "        print (img_data.shape)\n",
    "#         print (moment_data.shape)\n",
    "    else:\n",
    "        img_data= np.expand_dims(img_data, axis=3) \n",
    "#         moment_data= np.expand_dims(moment_data, axis=3) \n",
    "        print (img_data.shape)\n",
    "#         print (moment_data.shape)\n",
    "\n",
    "else:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.rollaxis(img_data,3,1)\n",
    "        print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1]), array([1152, 1128], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# convert class labels to on-hot encoding\n",
    "labels = np.array(labels_list)\n",
    "print(np.unique(labels,return_counts=True))\n",
    "Y = np_utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2052, 224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=4)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert train and test set to RGB\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_train = tf.image.grayscale_to_rgb(X_train)\n",
    "\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "X_test = tf.image.grayscale_to_rgb(X_test)\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(X_train)\n",
    "X_train = tf.make_ndarray(proto_tensor_val)\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(X_test)\n",
    "X_test = tf.make_ndarray(proto_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### VGG16 initialization ###\n",
    "from keras.models import Model\n",
    "# include top should be False to remove the softmax layer\n",
    "pretrained_model = VGG16()\n",
    "pretrained_model = Model(inputs=pretrained_model.inputs, outputs=pretrained_model.layers[-2].output)\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2052, 4096, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Feature extraction on train and val set\n",
    "\n",
    "vgg_features_train = pretrained_model.predict(X_train)\n",
    "vgg_features_val = pretrained_model.predict(X_test)\n",
    "\n",
    "vgg_features_train = vgg_features_train.reshape(vgg_features_train.shape[0], vgg_features_train.shape[1] ,1)\n",
    "vgg_features_val = vgg_features_val.reshape(vgg_features_val.shape[0], vgg_features_val.shape[1] ,1)\n",
    "\n",
    "vgg_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "\n",
    "## Fully Connected Layer ##\n",
    "model2 = Sequential()\n",
    "model2.add(Flatten(input_shape=(4096,1)))\n",
    "model2.add(Dense(100, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer=keras.optimizers.adam(lr=0.00004, decay= 1e-5), metrics=['accuracy'], loss='binary_crossentropy')\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "# train model using features generated from VGG16 model\n",
    "hist = model2.fit(vgg_features_train, y_train, epochs=100, batch_size=128, validation_data=(vgg_features_val, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving training output to csv file\n",
    "\n",
    "hist_df = pd.DataFrame(hist.history) \n",
    "hist_csv_file = 'history/test_VGG_history+Segmentation.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n",
    "history = pd.read_csv(\"history/test_VGG_history+Segmentation.csv\")\n",
    "val_loss = history['val_loss'].to_numpy()\n",
    "val_acc = history['val_accuracy'].to_numpy()\n",
    "loss = history['loss'].to_numpy()\n",
    "acc = history['accuracy'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Acc vs Loss graph ##\n",
    "plt.plot(acc)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Training Accuracy vs Loss (VGG16+Segmentation)', fontsize=20,)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Accuracy (%)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.legend(['Train_acc', 'Train_loss', 'Val_acc', 'Val_loss'], loc='best', fontsize=22)\n",
    "plt.gcf().set_size_inches(15,10) \n",
    "#plt.savefig('C:/Users/CooL/Desktop/Result/VGG/VGG_train_graph.jpg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Testing phase VGG16 ################\n",
    "\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/Testing_Set'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "test_list = []\n",
    "y_pred = []\n",
    "labels_name ={'Covid-19':0,'Non-Covid-19':1}\n",
    "\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    label_data = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        im= cv2.imread(data_path + '/'+ dataset + '/'+ img , 0)\n",
    "        ret1,th1 = cv2.threshold(im, 127,255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        h,w = im.shape[0:2]\n",
    "        mask = np.zeros(im.shape, dtype=np.uint8)\n",
    "\n",
    "        left = int(np.round(h/(2)))\n",
    "        right = int(np.round(h/(2)))\n",
    "        for y in range(left-int(h/5.2), left+int(h/3.9)):\n",
    "            for x in range(0, 4):\n",
    "                im[y][x] = 255\n",
    "\n",
    "        for y in range(right-int(h/5.2), right+int(h/3.9)):\n",
    "                for x in range(w-4, w):\n",
    "                    im[y][x] = 255\n",
    "\n",
    "        ## Binary image ##\n",
    "        binary = im < 150\n",
    "\n",
    "        ## Remove the blobs connected to the border of the image ##\n",
    "        cleared = clear_border(binary)\n",
    "\n",
    "        ## Label image ##\n",
    "        label_image = label(cleared)\n",
    "\n",
    "\n",
    "        ## Keep the labels with 2 largest areas ##\n",
    "        areas = [r.area for r in regionprops(label_image)]\n",
    "        areas.sort()\n",
    "\n",
    "\n",
    "        if len(areas) > 2:\n",
    "            for region in regionprops(label_image):\n",
    "                if region.area <= 5:\n",
    "                    for coordinates in region.coords: \n",
    "                        label_image[coordinates[0], coordinates[1]] = 0\n",
    "                        mask[coordinates[0], coordinates[1]] = 255\n",
    "\n",
    "\n",
    "        large_binary = label_image > 0  \n",
    "\n",
    "        ## Erosion operation with a disk of radius 2. This operation is seperate the lung nodules attached to the blood vessels ##\n",
    "        selem = disk(0)\n",
    "        binary_eroded = binary_erosion(large_binary, selem)\n",
    "\n",
    "\n",
    "        ## Closure operation with a disk of radius 10. This operation is to keep nodules attached to the lung wall ##\n",
    "        selem = disk(10)\n",
    "        binary_closed = binary_closing(binary_eroded, selem)\n",
    "\n",
    "        start_point = (0, 0) \n",
    "        end_point = (0,h) \n",
    "        color = (0,0,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point, end_point, color, 5)\n",
    "\n",
    "        start_point2 = (w, 0) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, h) \n",
    "        end_point2 = (w,h) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "        start_point2 = (0, 0) \n",
    "        end_point2 = (w,0) \n",
    "        binary_closed = cv2.line(np.float32(binary_closed), start_point2, end_point2, color, 5)\n",
    "\n",
    "\n",
    "        ## Fill in the small holes inside the binary mask of lungs ##\n",
    "        edges = roberts(binary_closed)\n",
    "        hole_closed = ndi.binary_fill_holes(edges)\n",
    "\n",
    "        ## Superimpose the binary mask on the input image. ##\n",
    "        ZERO_VALUE = 0\n",
    "        get_high_vals = (hole_closed == 0)\n",
    "        im[get_high_vals] = ZERO_VALUE # minimum value\n",
    "        \n",
    "                \n",
    "        input_img_resize=cv2.resize(im,(224,224))\n",
    "        test_list.append(input_img_resize)\n",
    "        y_pred.append(label_data)\n",
    "\n",
    "test_image = np.array(test_list)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "\n",
    "if num_channel==1:\n",
    "    if K.common.image_dim_ordering()=='th':\n",
    "        test_image= np.expand_dims(test_image, axis=1) \n",
    "        print (img_data.shape)\n",
    "    else:\n",
    "        test_image= np.expand_dims(test_image, axis=3) \n",
    "        #print (test_image.shape)\n",
    "\n",
    "else:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        test_image=np.rollaxis(test_image,3,1)\n",
    "        print (test_image.shape)\n",
    "    else:\n",
    "        test_image= np.expand_dims(test_image, axis=0)\n",
    "        print (test_image.shape)\n",
    "        \n",
    "## Convert train and test set to RGB\n",
    "test_image = tf.convert_to_tensor(test_image)\n",
    "test_image = tf.image.grayscale_to_rgb(test_image)\n",
    "\n",
    "proto_tensor_val = tf.make_tensor_proto(test_image)\n",
    "test_image = tf.make_ndarray(proto_tensor_val)\n",
    "\n",
    "## Feature extraction on test images ##\n",
    "test_features = pretrained_model.predict(test_image)\n",
    "\n",
    "\n",
    "test_features = test_features.reshape(200,4096,1)\n",
    "predict_list = []\n",
    "predict_1 = model2.predict_proba(test_features)\n",
    "\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_pred, predict_1[:,1])\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import pandas as pd\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "optimum = thresholds_keras[np.argmax(tpr_keras - fpr_keras)]\n",
    "print('Optimal cut off point = ',optimum)\n",
    "print('AUC = ', auc_keras)\n",
    "\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "ix = np.argmax(gmeans)\n",
    "optimal = thresholds_keras[ix]\n",
    "print('Optimal cut off point = ',thresholds_keras[ix])\n",
    "\n",
    "x = optimal # Best => x = 0.98892\n",
    "\n",
    "# for j in range(0,1):\n",
    "#     for i in range(0, len(predict_1)):\n",
    "#         if predict_1[i][1] >= x:\n",
    "#             predict_list.append(1)\n",
    "#         else:\n",
    "#             predict_list.append(0)\n",
    "#     print(confusion_matrix(y_pred, predict_list), 'x =',\"%.5f\" % x, '\\n')\n",
    "\n",
    "cf_matrix=confusion_matrix(y_pred, predict_list)\n",
    "tp = cf_matrix[0][0]\n",
    "fn = cf_matrix[0][1]\n",
    "fp = cf_matrix[1][0]\n",
    "tn = cf_matrix[1][1]\n",
    "\n",
    "TrueP = '{0:.2%}'.format(tp/(tp+fn))\n",
    "FalseN = '{0:.2%}'.format(fn/(tp+fn))\n",
    "FalseP = '{0:.2%}'.format(fp/(fp+tn))\n",
    "TrueN = '{0:.2%}'.format(tn/(fp+tn))\n",
    "print(TrueP, FalseN, FalseP, TrueN)\n",
    "\n",
    "xy_Labels = ['Covid', 'non-Covid']\n",
    "group_names = ['True Positive', 'False Negative', 'False Positive','True Negative']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentage = [TrueP, FalseN, FalseP, TrueN]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentage)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "### Confusion Matrix VGG16+Segmentation ###\n",
    "# plt.title('(VGG-16), Threshold = '+str(\"{:.4f}\".format(optimal)), fontsize = 20)\n",
    "plt.title('Confusion Matrix (VGG-16)',fontsize = 18)\n",
    "sns.heatmap(cf_matrix, fmt='', annot=labels, annot_kws={'size':18} ,xticklabels=xy_Labels, yticklabels=xy_Labels, cmap='Blues')\n",
    "plt.xlabel('Predicted label', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True label', fontsize = 15) # y-axis label with fontsize 15\n",
    "plt.show()\n",
    "\n",
    "### ROC Curves VGG16+Segmentation ###\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix],tpr_keras[ix], marker='o', color='black', label='Optimal Threshold = {:.4f})'.format(optimal))\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.title('ROC (VGG-16)',fontsize=22)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
