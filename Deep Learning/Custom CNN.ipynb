{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "# from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten  \n",
    "# from keras.layers import concatenate\n",
    "from keras.layers import *\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getcwd()\n",
    "\n",
    "### Define data path  ###\n",
    "data_path = PATH + '/CT'\n",
    "data_dir_list = os.listdir(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pre-Processing ###\n",
    "img_rows=224\n",
    "img_cols=224\n",
    "num_channel=1\n",
    "num_epoch=20\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 2\n",
    "labels_name={'Covid':0,'non-Covid':1}\n",
    "\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "moment_list = []\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
    "    label = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        ## Image processing using openCV ##\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "        input_img_gray=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "        input_img_resize_gray = cv2.resize(input_img_gray,(224,224))\n",
    "#         #ret,input_img = cv2.threshold(input_img,100,255,cv2.THRESH_BINARY)\n",
    "#         ret,input_img = cv2.threshold(input_img, 120,255, cv2.THRESH_TOZERO)\n",
    "#         #ret,input_img = cv2.threshold(input_img,100,255, cv2.THRESH_TOZERO_INV)\n",
    "#         #ret,input_img = cv2.threshold(input_img, 150,255,cv2.THRESH_TRUNC)\n",
    "        input_img_resize=cv2.resize(input_img,(224,224))\n",
    "        moments = cv2.moments(input_img_resize_gray)\n",
    "        huMoments = cv2.HuMoments(moments)   \n",
    "        moment_list.append(huMoments)\n",
    "        img_data_list.append(input_img_resize)\n",
    "        labels_list.append(label)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image normalization ###\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "moment_data = np.array(moment_list)\n",
    "moment_data = moment_data.astype('float32')\n",
    "moment_data /= 255\n",
    "print (img_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting label to categorical label\n",
    "from keras.utils.np_utils import to_categorical\n",
    "labels = np.array(labels_list)\n",
    "# print the count of number of samples for different classes\n",
    "print(np.unique(labels,return_counts=True))\n",
    "# convert class labels to on-hot encoding\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Channel expansion ### *For images using RGB only\n",
    "moment_data= np.expand_dims(moment_data, axis=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Expanding colour channel ### *For images using Gray only\n",
    "\n",
    "if num_channel==1:\n",
    "    if K.common.image_dim_ordering()=='th':\n",
    "        img_data= np.expand_dims(img_data, axis=1) \n",
    "            moment_data= np.expand_dims(moment_data, axis=1) \n",
    "        print (img_data.shape)\n",
    "            print (moment_data.shape)\n",
    "    else:\n",
    "        img_data= np.expand_dims(img_data, axis=3) \n",
    "            moment_data= np.expand_dims(moment_data, axis=3) \n",
    "        print (img_data.shape)\n",
    "            print (moment_data.shape)\n",
    "\n",
    "else:\n",
    "    if K.image_dim_ordering()=='th':\n",
    "        img_data=np.rollaxis(img_data,3,1)\n",
    "        print (img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Splitting ###\n",
    "#Shuffle the dataset\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "x2,y2 = shuffle(moment_data,Y, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.1, random_state=2)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom CNN configuration ##\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.adam(lr=0.0004 , decay= 1e-5) ,metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#model.save('model/CNN_Classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training parameters saving ##\n",
    "import pandas as pd\n",
    "hist_df = pd.DataFrame(hist.history) \n",
    "\n",
    "hist_csv_file = 'history/CNN_history2.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv(\"history/CNN_history2.csv\")\n",
    "val_loss = history['val_loss'].to_numpy()\n",
    "val_acc = history['val_accuracy'].to_numpy()\n",
    "loss = history['loss'].to_numpy()\n",
    "acc = history['accuracy'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(acc)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_acc)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Training Accuracy', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.ylabel('Accuracy (%)', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.xlabel('Epoch',fontsize=20)\n",
    "plt.legend(['Train_acc', 'Train_loss', 'Val_acc', 'Val_loss'], loc='best', fontsize=22)\n",
    "plt.gcf().set_size_inches(12,13) \n",
    "plt.savefig('# Acc vs Loss graph path #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading saved trained CNN model ##\n",
    "#model = keras.models.load_model('model/CNN_Classifier.h5')\n",
    "\n",
    "#### Testing phase (Without moment invariant) ####\n",
    "PATH = os.getcwd()\n",
    "data_path = PATH + '/Testing_Set'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "test_list = []\n",
    "y_pred = []\n",
    "labels_name ={'Covid':0,'non-Covid':1}\n",
    "\n",
    "#ret,thresh3 = cv2.threshold(input_img,200,255,cv2.THRESH_TRUNC)\n",
    "\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    label = labels_name[dataset]\n",
    "    for img in img_list:\n",
    "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "#         input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
    "#         #ret,input_img = cv2.threshold(input_img,100,255,cv2.THRESH_BINARY)\n",
    "#         ret,input_img = cv2.threshold(input_img, 120,255, cv2.THRESH_TOZERO)\n",
    "        input_img_resize=cv2.resize(input_img,(224,224))\n",
    "        test_list.append(input_img_resize)\n",
    "        y_pred.append(label)\n",
    "\n",
    "test_image = np.array(test_list)\n",
    "test_image = test_image.astype('float32')\n",
    "test_image /= 255\n",
    "\n",
    "## For gray images only ##\n",
    "# if num_channel==1:\n",
    "#     if K.common.image_dim_ordering()=='th':\n",
    "#         test_image= np.expand_dims(test_image, axis=1) \n",
    "#         print (img_data.shape)\n",
    "#     else:\n",
    "#         test_image= np.expand_dims(test_image, axis=3) \n",
    "#         #print (test_image.shape)\n",
    "\n",
    "# else:\n",
    "#     if K.image_dim_ordering()=='th':\n",
    "#         test_image=np.rollaxis(test_image,3,1)\n",
    "#         print (test_image.shape)\n",
    "#     else:\n",
    "#         test_image= np.expand_dims(test_image, axis=0)\n",
    "#         print (test_image.shape)\n",
    "\n",
    "\n",
    "predict_list = []\n",
    "predict_1 = model.predict_proba(test_image) ## Probability prediction ##\n",
    "\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import pandas as pd\n",
    "\n",
    "### ROC Curves ###\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_pred, predict_1[:,1])\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "optimum = thresholds_keras[np.argmax(tpr_keras - fpr_keras)]\n",
    "print('Optimal cut off point = ',optimum)\n",
    "print('AUC = ', auc_keras)\n",
    "\n",
    "gmeans = np.sqrt(tpr_keras * (1-fpr_keras))\n",
    "ix = np.argmax(gmeans)\n",
    "optimal = thresholds_keras[ix]\n",
    "print('Optimal cut off point = ',thresholds_keras[ix]) ## Optimal point ##\n",
    "\n",
    "x = optimal # Best => x = 0.98892\n",
    "\n",
    "# for j in range(0,1):\n",
    "#     for i in range(0, len(predict_1)):\n",
    "#         if predict_1[i][1] >= x:\n",
    "#             predict_list.append(1)\n",
    "#         else:\n",
    "#             predict_list.append(0)\n",
    "#     print(confusion_matrix(y_pred, predict_list), 'x =',\"%.5f\" % x, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cf_matrix= confusion_matrix(y_pred, predict_list)\n",
    "# cf = cf_matrix\n",
    "# cm_sum = np.sum(cf_matrix, axis=1, keepdims=True) \n",
    "# cm_perc = cf_matrix / cm_sum.astype(float) * 100\n",
    "# annot = np.empty_like(cf_matrix).astype(str)\n",
    "# nrows, ncols = cf_matrix.shape\n",
    "# for i in range(nrows):\n",
    "#     for j in range(ncols):\n",
    "#         c = cf_matrix[i, j]\n",
    "#         p = cm_perc[i, j]\n",
    "#         if i == j:\n",
    "#             s = cm_sum[i]\n",
    "#             annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "#         elif c == 0:\n",
    "#             annot[i, j] = ''\n",
    "#         else:\n",
    "#             annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "# cf_matrix = pd.DataFrame(cf_matrix, index=labels, columns=labels)\n",
    "# print(cm_perc)\n",
    "tp = cf_matrix[0][0]\n",
    "fn = cf_matrix[0][1]\n",
    "fp = cf_matrix[1][0]\n",
    "tn = cf_matrix[1][1]\n",
    "\n",
    "TrueP = '{0:.2%}'.format(tp/(tp+fn))\n",
    "FalseN = '{0:.2%}'.format(fn/(tp+fn))\n",
    "FalseP = '{0:.2%}'.format(fp/(fp+tn))\n",
    "TrueN = '{0:.2%}'.format(tn/(fp+tn))\n",
    "print(TrueP, FalseN, FalseP, TrueN)\n",
    "\n",
    "xy_Labels = ['Covid', 'non-Covid']\n",
    "group_names = ['True Positive', 'False Negative', 'False Positive','True Negative']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n",
    "group_percentage = [TrueP, FalseN, FalseP, TrueN]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentage)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "### Confusion matrix ###\n",
    "# plt.title('(CNN), Threshold = '+str(\"{:.4f}\".format(optimal)), fontsize = 20)\n",
    "plt.title('Confusion Matrix (Custom CNN)',fontsize = 18)\n",
    "sns.heatmap(cf_matrix, fmt=\"\", annot=labels, annot_kws={'size':18} ,xticklabels=xy_Labels, yticklabels=xy_Labels, cmap='Blues')\n",
    "plt.xlabel('Predicted label', fontsize = 15) # x-axis label with fontsize 15\n",
    "plt.ylabel('True label', fontsize = 15) # y-axis label with fontsize 15\n",
    "plt.savefig('## Path saving CF')\n",
    "plt.show()\n",
    "\n",
    "### ROC graph ###\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))\n",
    "plt.scatter(fpr_keras[ix],tpr_keras[ix], marker='o', color='black', label='Optimal Threshold = {:.4f})'.format(optimal))\n",
    "plt.xlabel('False positive rate (FPR)', fontsize=15)\n",
    "plt.ylabel('True positive rate (TPR)', fontsize=15)\n",
    "plt.title('ROC (CNN)',fontsize=22)\n",
    "plt.legend(loc='best', fontsize=15)\n",
    "plt.savefig('## Path saving ROC Curves')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model.save('model/CNN_Threshold_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
